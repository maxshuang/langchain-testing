{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './embedding_exam.txt'}, page_content='Line 1: The autumn leaves danced in the crisp wind\\nLine 2: A silver teapot whistled on the stove\\nLine 3: Distant thunder rumbled across the valley\\nLine 4: Children laughed while playing in the park\\nLine 5: Stars twinkled like diamonds in the night sky\\nLine 6: Waves crashed gently against the sandy shore\\nLine 7: A clock ticked steadily on the wall\\nLine 8: Fresh bread filled the kitchen with warmth\\nLine 9: Birds soared gracefully through cotton clouds\\nLine 10: The old bookshelf creaked with stories untold')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"./embedding_exam.txt\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.langchain.com/', 'title': 'LangChain', 'description': 'LangChain’s suite of products supports developers along each step of their development journey.', 'language': 'en'}, page_content=\"LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nLangChainLangSmithLangGraphMethods\\n\\nRetrievalAgentsEvaluationResources\\n\\nBlogCustomer StoriesLangChain AcademyCommunityExpertsChangelogLLM Evaluations GuideState of AI AgentsBreakout Agent StoriesDocs\\n\\nPythonLangChainLangSmithLangGraphJavaScriptLangChainLangSmithLangGraphCompany\\n\\nAboutCareersPricing\\n\\nLangSmithLangGraph PlatformGet a demoSign up\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProducts\\n\\nLangChainLangSmithLangGraphMethods\\n\\nRetrievalAgentsEvaluationResources\\n\\nBlogCustomer StoriesLangChain AcademyCommunityExpertsChangelogLLM Evaluations GuideState of AI AgentsBreakout Agent StoriesDocs\\n\\nPythonLangChainLangSmithLangGraphJavaScriptLangChainLangSmithLangGraphCompany\\n\\nAboutCareersPricing\\n\\nLangSmithLangGraph PlatformGet a demoSign upLangChain’s suite of products supports developers along each step of the LLM application lifecycle.Applications that can reason. Powered by LangChain.Get a demoSign up for free\\n\\nFrom startups to global enterprises, ambitious builders choose LangChain products.BuildLangChain is a composable framework to build with LLMs. LangGraph is the orchestration framework for controllable agentic workflows.RunDeploy your LLM applications at scale with LangGraph Platform, our infrastructure purpose-built for agents.ManageDebug, collaborate, test, and monitor your LLM app in LangSmith - whether it's built with a LangChain framework or not.\\xa0\\n\\n\\n\\nBuild your app with LangChainBuild context-aware, reasoning applications with LangChain’s flexible framework that leverages your company’s data and APIs. Future-proof your application by making vendor optionality part of your LLM infrastructure design.Learn more about LangChain\\n\\n\\n\\n\\nRun at scale with LangGraph\\xa0PlatformUse LangGraph Platform’s APIs to design agent-driven user experiences featuring human-in-the-loop, multi-agent collaboration, conversation history, long-term memory, and time-travel. Deploy with fault-tolerant scalability.\\n\\n\\nLearn more about LangGraph\\xa0Platform\\n\\nManage LLM performance with\\xa0LangSmithShip faster with LangSmith’s debug, test, deploy, and monitoring workflows. Don’t rely on “vibes” – add engineering rigor to your LLM-development workflow, whether you’re building with LangChain or not.Learn more about LangSmith\\n\\n\\nHear from our happy customersLangChain, LangGraph, and LangSmith help teams of all sizes, across all industries - from ambitious startups to established enterprises.“LangSmith helped us improve the accuracy and performance of Retool’s fine-tuned models. Not only did we deliver a better product by iterating with LangSmith, but we’re shipping new AI features to our users in a fraction of the time it would have taken without it.”Jamie CuffeHead of Self-Serve and New Products“By combining the benefits of LangSmith and standing on the shoulders of a gigantic open-source community, we’re able to identify the right approaches of using LLMs in an enterprise-setting faster.”Yusuke KajiGeneral Manager of AI“Working with LangChain and LangSmith on the Elastic AI Assistant had a significant positive impact on the overall pace and quality of the development and shipping experience. We couldn’t have achieved \\xa0the product experience delivered to our customers without LangChain, and we couldn’t have done it at the same pace without LangSmith.”James SpiteriDirector of Security Products“As soon as we heard about LangSmith, we moved our entire development stack onto it. We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.”Jose PeñaSenior Manager\\n\\n\\n\\n\\n\\n\\n\\n\\nThe reference architecture enterprises adopt for success.LangChain’s suite of products can be used independently or stacked together for multiplicative impact – guiding you through building, running, and managing your LLM apps.15M+Monthly Downloads100K+Apps Powered100K+GitHub Stars4K+ContributorsThe biggest developer community in GenAILearn alongside the 1M+ developers who are pushing the industry forward.Explore LangChain\\n\\n\\nGet started with the LangSmith platform todayGet a demoSign up for freeTeams building with LangChain are driving operational efficiency, increasing discovery & personalization, and delivering premium products that generate revenue.See customer stories\\n\\n\\nGet inspired by companies who have done it.Financial Services\\n\\n\\nFinTech\\n\\n\\nTechnology\\n\\n\\nLangSmith is the enterprise\\xa0developer platform\\xa0built for LLMs.Explore LangSmith\\n\\n\\n\\n\\nGain visibility to make trade offs between cost, latency, and quality.\\n\\nIncrease developer productivity.\\n\\nEliminate manual, error-prone testing.\\n\\nReduce hallucinations and improve reliability.\\n\\nEnterprise deployment options to keep data secure.Ready to start shipping \\u2028reliable GenAI apps faster?Get started with LangChain, LangSmith, and LangGraph to enhance your LLM app development, from prototype to production.Get a demoSign up for freeProductsLangChainLangSmithLangGraphAgentsEvaluationRetrievalResourcesPython DocsJS/TS DocsGitHubIntegrationsChangelogCommunityLangSmith Trust PortalCompanyAboutCareersBlogTwitterLinkedInYouTubeMarketing AssetsSign up for our newsletter to stay up to dateThank you! Your submission has been received!Oops! Something went wrong while submitting the form.All systems operationalPrivacy PolicyTerms of Service\\n\\n\\n\\n\\n\\n\\n\")]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.langchain.com/\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the pdf parsing library\n",
    "#pip install pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"./test.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Line 1: The autumn leaves danced in the crisp wind\n",
      "Line 2: A silver teapot whistled on the stove\n",
      "Line 3: Distant thunder rumbled across the valley\n",
      "Line 4: Children laughed while playing in the park\n",
      "Line 5: Stars twinkled like diamonds in the night sky\n",
      "Line 6: Waves crashed gently against the sandy shore\n",
      "Line 7: A clock ticked steadily on the wall\n",
      "Line 8: Fresh bread filled the kitchen with warmth\n",
      "Line 9: Birds soared gracefully through cotton clouds\n",
      "Line 10: The old bookshelf creaked with stories untold' metadata={'source': './embedding_exam.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"./embedding_exam.txt\") # or any other loader\n",
    "docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # characters\n",
    "    chunk_overlap=200, # some overlap between chunks of 200 characters to maintain some context\n",
    ")\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "# Verify split documents\n",
    "for doc in splitted_docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.langchain.com'}, page_content='# LangChain'),\n",
       " Document(metadata={'source': 'https://www.langchain.com'}, page_content='Building applications with LLMs through composability'),\n",
       " Document(metadata={'source': 'https://www.langchain.com'}, page_content='## Quick Install\\n```bash\\npip install langchain'),\n",
       " Document(metadata={'source': 'https://www.langchain.com'}, page_content='```'),\n",
       " Document(metadata={'source': 'https://www.langchain.com'}, page_content='As an open-source project in a rapidly developing field, we'),\n",
       " Document(metadata={'source': 'https://www.langchain.com'}, page_content='are extremely open to contributions.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "# LangChain\n",
    "Building applications with LLMs through composability \n",
    "## Quick Install\n",
    "```bash\n",
    "pip install langchain\n",
    "```\n",
    "As an open-source project in a rapidly developing field, we are extremely open to contributions.\n",
    "\"\"\"\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "md_docs = md_splitter.create_documents([markdown_text], [{\"source\": \"https://www.langchain.com\"}])\n",
    "md_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "model = OpenAIEmbeddings()\n",
    "embeddings = model.embed_documents([\n",
    "    \"Hi there!\",\n",
    "    \"Oh, hello!\",\n",
    "    \"What's your name?\",\n",
    "    \"My friends call me World\",\n",
    "    \"Hello World!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(doc)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m## Generate embeddings\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embeddings_model\u001b[38;5;241m.\u001b[39membed_documents(chunk\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m[[0.0053587136790156364,\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m -0.0004999046213924885,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m -0.00900818221271038, ...], ...]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:338\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy)\n\u001b[1;32m    337\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39membeddings  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "## Load the document \n",
    "loader = TextLoader(\"./embedding_exam.txt\")\n",
    "doc = loader.load()\n",
    "\"\"\"\n",
    "[\n",
    "    Document(page_content='Document loaders\\n\\nUse document loaders to load data from a source as `Document`\\'s. A `Document` is a piece of text\\nand associated metadata. For example, there are document loaders for loading a simple `.txt` file, for loading the text\\ncontents of any web page, or even for loading a transcript of a YouTube video.\\n\\nEvery document loader exposes two methods:\\n1. \"Load\": load documents from the configured source\\n2. \"Load and split\": load documents from the configured source and split them using the passed in text splitter\\n\\nThey optionally implement:\\n\\n3. \"Lazy load\": load documents into memory lazily\\n', metadata={'source': 'test.txt'})\n",
    "]\n",
    "\"\"\"\n",
    "## Split the document\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "chunks = text_splitter.split_documents(doc)\n",
    "## Generate embeddings\n",
    "model = OpenAIEmbeddings()\n",
    "embeddings = model.embed_documents(chunk.page_content for chunk in chunks)\n",
    "\"\"\"\n",
    "[[0.0053587136790156364,\n",
    " -0.0004999046213924885,\n",
    " 0.038883671164512634,\n",
    " -0.003001077566295862,\n",
    " -0.00900818221271038, ...], ...]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
    "# Store the embedding vectors in pgvector\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "# Load the document, split it into chunks\n",
    "raw_documents = TextLoader('./test.txt').load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "# embed each chunk and insert it into the vector store\n",
    "model = OpenAIEmbeddings()\n",
    "connection = 'postgresql+psycopg://langchain:langchain@localhost:6024/langchain'\n",
    "db = PGVector.from_documents(documents, model, connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the N (in this case 4) previously stored embeddings that are most similar to your query\n",
    "db.similarity_search(\"query\", k=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39madd_documents([\n\u001b[1;32m      2\u001b[0m   Document(\n\u001b[1;32m      3\u001b[0m       page_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere are cats in the pond\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m       metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpond\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manimals\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      5\u001b[0m   ),\n\u001b[1;32m      6\u001b[0m   Document(\n\u001b[1;32m      7\u001b[0m       page_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mducks are also found in the pond\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m       metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpond\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manimals\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      9\u001b[0m   ),\n\u001b[1;32m     10\u001b[0m ], ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Add more documents into the DB\n",
    "db.add_documents([\n",
    "  Document(\n",
    "      page_content=\"there are cats in the pond\",\n",
    "      metadata={\"location\": \"pond\", \"topic\": \"animals\"},\n",
    "  ),\n",
    "  Document(\n",
    "      page_content=\"ducks are also found in the pond\",\n",
    "      metadata={\"location\": \"pond\", \"topic\": \"animals\"},\n",
    "  ),\n",
    "], ids=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable deleting the documents by ids later\n",
    "db.delete(ids=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup mode for record manager:\n",
    "# None mode does not do any automatic cleanup, allowing the user to manually do cleanup of old content.\n",
    "# Incremental and full modes delete previous versions of the content if the content of the source document or derived documents has changed.\n",
    "# Full mode will additionally delete any documents not included in documents currently being indexed.\n",
    "\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace, db_url=\"postgresql+psycopg://langchain:langchain@localhost:6024/langchain\"\n",
    ")\n",
    "# Create the schema if it doesn't exist \n",
    "record_manager.create_schema()\n",
    "index(\n",
    "    [doc1Updated, doc2],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup='incremental',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python bitnet-cpp",
   "language": "python",
   "name": "bitnet-cpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

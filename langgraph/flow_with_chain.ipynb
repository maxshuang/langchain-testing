{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# useful to generate SQL query\n",
    "model_low_temp = ChatOpenAI(temperature=0.1)\n",
    "# useful to generate natural language outputs\n",
    "model_high_temp = ChatOpenAI(temperature=0.7)\n",
    "class State(TypedDict):\n",
    "    # to track conversation history\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # input\n",
    "    user_query: str\n",
    "    # output\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "class Output(TypedDict):\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "\n",
    "generate_prompt = SystemMessage(\n",
    "    \"You are a helpful data analyst, who generates SQL queries for users based on their questions.\"\n",
    ")\n",
    "\n",
    "def generate_sql(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [generate_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"sql_query\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }\n",
    "\n",
    "explain_prompt = SystemMessage(\n",
    "    \"You are a helpful data analyst, who explains SQL queries to users.\"\n",
    ")\n",
    "\n",
    "def explain_sql(state: State) -> State:\n",
    "    messages = [\n",
    "        explain_prompt,\n",
    "        # contains user's query and SQL query from prev step\n",
    "        *state[\"messages\"],\n",
    "    ]\n",
    "    res = model_high_temp.invoke(messages)\n",
    "    return {\n",
    "        \"sql_explanation\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }\n",
    "\n",
    "builder = StateGraph(State, input=Input, output=Output)\n",
    "builder.add_node(\"generate_sql\", generate_sql)\n",
    "builder.add_node(\"explain_sql\", explain_sql)\n",
    "builder.add_edge(START, \"generate_sql\")\n",
    "builder.add_edge(\"generate_sql\", \"explain_sql\")\n",
    "builder.add_edge(\"explain_sql\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\n",
    "  \"user_query\": \"What is the total sales for each product?\"\n",
    "})\n",
    "\n",
    "#{\n",
    "#  \"sql_query\": \"SELECT product_name, SUM(sales_amount) AS total_sales\\nFROM sales\\nGROUP BY product_name;\",\n",
    "#  \"sql_explanation\": \"This query will retrieve the total sales for each product by summing up the sales_amount column for each product and grouping the results by product_name.\",\n",
    "#}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python bitnet-cpp",
   "language": "python",
   "name": "bitnet-cpp"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
